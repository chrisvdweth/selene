{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3befb2a-fd8b-495f-a037-71a98878618b",
   "metadata": {},
   "source": [
    "<img src=\"images/logo/selene-logo-640.png\" style=\"max-height:75px;\" alt=\"SELENE Logo\" />\n",
    "\n",
    "**Disclaimer:** This Jupyter Notebook contains content generated with the assistance of AI. While every effort has been made to review and validate the outputs, users should independently verify critical information before relying on it. The SELENE notebook repository is constantly evolving. We recommend downloading or pulling the latest version of this notebook from Github."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1882f62-1168-4513-bb8c-1c84040265ba",
   "metadata": {},
   "source": [
    "# Porter Stemmer\n",
    "\n",
    "The Porter Stemmer is a popular algorithm used in natural language processing (NLP) and information retrieval to reduce words to their base or root form. It was developed by Martin Porter in 1980 and is one of the most widely used stemming algorithms due to its simplicity and effectiveness. The primary purpose of stemming is to group together words with the same root meaning, enabling text analysis systems to treat variations of a word (e.g., \"running,\" \"runs,\" \"runner\") as a single term (\"run\"). This process helps improve the efficiency of search engines, text mining, and other NLP tasks.\n",
    "\n",
    "The algorithm works by systematically applying a series of rules to remove or modify suffixes from words. These rules are organized into steps, each targeting specific suffix patterns, such as \"-ing,\" \"-ed,\" or \"-ly.\" For example, the word \"playing\" would be reduced to \"play,\" and \"happiness\" to \"happi.\" The rules are designed to ensure that the stemmed word retains its linguistic meaning and can be understood in context, although the resulting stems are not guaranteed to be valid words.\n",
    "\n",
    "Despite its strengths, the Porter Stemmer has some limitations. It uses heuristic rules, which means it can sometimes produce stems that are not semantically meaningful or recognizable. For instance, words like \"university\" may be stemmed to \"univers,\" which is not an actual word. Additionally, the algorithm is language-specific and primarily designed for English. For other languages, different stemming algorithms may be needed to account for unique morphological structures.\n",
    "\n",
    "In modern NLP applications, stemming is often supplemented or replaced by lemmatization, which is a more sophisticated process that reduces words to their dictionary base form (lemma) using linguistic rules and vocabulary. However, the Porter Stemmer remains relevant in many cases where computational efficiency and simplicity are prioritized, such as in lightweight search engines or preprocessing pipelines for text analysis. Its enduring popularity highlights its significance in the evolution of text processing techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16be1283-cb84-4395-a08d-733353c476de",
   "metadata": {},
   "source": [
    "### Setting up the Notebook\n",
    "\n",
    "#### Make Required Imports\n",
    "\n",
    "This notebook requires the import of different Python packages but also additional Python modules that are part of the repository. If a package is missing, use your preferred package manager (e.g., [conda](https://anaconda.org/anaconda/conda) or [pip](https://pypi.org/project/pip/)) to install it. If the code cell below runs with any errors, all required packages and modules have successfully been imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "141b6c0c-0469-45a7-a5c2-2dfd6e3968e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.text.preprocessing.stemming import MyPorterStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8babdc3-6f88-4b56-8ad7-08f5500f7504",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5d7bb8-c486-44f1-a1ae-9254a7f31353",
   "metadata": {},
   "source": [
    "## Algorithm\n",
    "\n",
    "In this notebook, we discuss in detail the original proposed [Porter Stemmer](https://tartarus.org/martin/PorterStemmer/index.html) algorithm. This includes that we use the same notations used in this description of the algorithm. The implementation of the Porter Stemmer used throughout the notebook is taken and adopted from the [NLTK implementation](https://www.nltk.org/_modules/nltk/stem/porter.html) of the algorithm. This implementation includes extensions to the algorithm; those have been removed to simplify the code and to match the implementation with the originally proposed algorithm.\n",
    "\n",
    "Let's create an instance of the class `MyPorterStemmer` to show examples throughout the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4019410-a32c-4504-846a-30df0f8794b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = MyPorterStemmer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741a90c3-2604-4508-9845-4fc903d499cc",
   "metadata": {},
   "source": [
    "### Representation of Words\n",
    "\n",
    "The Porter Stemmer converts a word into a sequence of c's (consonants) and v's (vowels) as part of its internal mechanism to simplify the process of identifying patterns in word structure. This transformation is not an output of the stemmer but a representation used during intermediate steps for rule application. The purpose is to provide a structured way to analyze and manipulate the word's morphology. Here's why this is done:\n",
    "\n",
    "* **Identifying Structural Patterns:** Words in English often follow predictable patterns of alternating vowels and consonants. By representing a word as a sequence of c's and v's, the algorithm can focus on identifying these patterns more abstractly. For instance, the word *\"running\"* is represented `cvccvcc` (*\"r\"* is a consonant, *\"u\"* a vowel, *\"n\"* a consonant, and so on). The word *\"aggressiveness\"* is represented as `vcccvccvcvcvcc`. These c-v sequences are then further transformed by aggregating all sequences of c's into a single `C`, and all sequences of v's into a single `V`. This means that `cvccvcc` becomes `CVCVC`, and `vcccvccvcvcvcc` becomes `VCVCVCVCVC`. This abstract representation allows the algorithm to apply rules based on the sequence's structure, rather than directly working with specific letters.\n",
    "\n",
    "* **Facilitating Rule-Based Operations:** Many stemming rules in the Porter algorithm depend on the length and arrangement of vowel and consonant sequences. For example, a rule might only apply if a word has at least one `VC` sequence (e.g., *\"abate\"* has the sequence `VCVC` and meets this criterion, while *\"ate\"* does not). Another rule might target words ending in a specific suffix preceded by a `VC` structure, such as *\"-ing\"* in *\"playing\"*. By abstracting words into c-v sequences, the algorithm can generalize these rules and make decisions without considering the complexity of individual letters.\n",
    "\n",
    "The method of `_cv_sequence()` of the class `MyPorterStemmer` implements this transformation of words into their internal representation for the stemming algorithm. Notice that this methods does not combine sequences of c's and v's into single a `C` and `V`. For example, for the word *\"running\"* the method will return `cvccvcc` and not `CVCVC`. For implementation purposes this last transformation step is not needed; as we will see in a bit.\n",
    "\n",
    "Use the code cell below to call the `_cv_sequence()` on different example words and observe the output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e0b850c-132f-4725-988c-606290fe9de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vcccvccvcvcvcc\n"
     ]
    }
   ],
   "source": [
    "word = \"running\"\n",
    "word = \"aggressiveness\"\n",
    "\n",
    "print(stemmer._cv_sequence(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262a4f7b-b06f-4c63-87f4-00d8d1f91922",
   "metadata": {},
   "source": [
    "### Determining the \"Measure\" (m)\n",
    "\n",
    "A key concept in the Porter Stemmer is the Measure (m), which counts the number of `VC` sequences in a word. Notice that, using the `VC` representation, each word can be represented as\n",
    "\n",
    "$$\\large\n",
    "[C](VC)^m[V]\n",
    "$$\n",
    "\n",
    "where the square brackets denote an arbitrary presence of consonants or vowels, and $(VC)^m$ denotes $VC$ repeated $m$ times. For example:\n",
    "\n",
    "* The word *\"aggressiveness\"* has a measure of $m=5$ since `VCVCVCVCVC`contains five `VC` pairs.\n",
    "* The word *\"running\"* has a measure of $m=5$ since `CVCVC`contains five `VC` pairs.\n",
    "* The word *\"run\"* has a measure of $m=1$ since `CVC` contains only one `VC` pair.\n",
    "* The word *\"see\"* has a measure of $m=0$ since `CVV` contains no `VC` pair.\n",
    "\n",
    "This measure is critical for deciding whether a suffix should be removed. For example, a suffix like *\"-ing\"* is removed only if the stemmed word has a measure greater than $1$. This prevents over-stemming and ensures meaningful stems.\n",
    "\n",
    "The method `_measure()` implements the calculation of the measure $m$. Again, use the code cell below and try different words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1dee55a-ceb9-4dff-9988-73a7e8efb4fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "word = \"aggressiveness\"\n",
    "#word = \"running\"\n",
    "#word = \"run\"\n",
    "#word = \"see\"\n",
    "\n",
    "print(stemmer._measure(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f69071-dadf-4a68-96ae-8441277b6a3b",
   "metadata": {},
   "source": [
    "If you check out the code for method `_measure()`, you will notice that it simply calls the method `_cv_sequence()` and then counts the number of occurrences of the substring `vc`. Recall that `_cv_sequence()` return, say for the word *\"aggressiveness\"* the sequence `vcccvccvcvcvcc` and not `VCVCVCVCVC`. However the number of occurrences of `vc` in `vcccvccvcvcvcc` will always be the same as the number of occurrences of `VC` in `VCVCVCVCVC`. This is why we do not need to merge sequences of c's and v's in practice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32633313-c543-422c-bfd5-f1d39371a0c8",
   "metadata": {},
   "source": [
    "### Rules\n",
    "\n",
    "A rule in the Porter Stemmer algorithm is a specific pattern-based instruction used to transform a word by removing or modifying its suffix. These rules are designed to simplify the word while retaining its root meaning for tasks like text analysis or search. The rules operate in a systematic, step-by-step process, targeting different suffixes and conditions at each stage. The general syntax of a rules is:\n",
    "\n",
    "$$\\large\n",
    "(condition)\\ S1 \\rightarrow S1\n",
    "$$\n",
    "\n",
    "This means that if a word ends with the suffix $S1$, and the stem before $S1$ satisfies the given $condition$, $S1$ is replaced by $S2$. The condition is usually given in terms of measure $m$ in regard to the stem before $S1$. For example, consider the rule\n",
    "\n",
    "$$\\large\n",
    "(m > 1)\\ EMENT \\rightarrow\n",
    "$$\n",
    "\n",
    "Here $S1$ is *\"EMENT\"* and $S2$ is null. This would map *\"REPLACEMENT\"* to *\"REPLAC\"*, since *\"REPLAC\"* is a word part for which $m = 2$. In contrast, the word *\"CEMENT\"* would remain unchanged since the part before *\"EMENT\"* (i.e., *\"C\"*) has a measure of $m = 0$ which does not satisfy the condition.\n",
    "\n",
    "**Side note:** In the original algorithm description all rules are defined using capital letters. However, in practice, the rules are case-insensitive. However, to align with the original description we adhere to the notation of using capital letters in rules."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea3db11-9c12-4492-b7df-fd18e333a608",
   "metadata": {},
   "source": [
    "### Conditions\n",
    "\n",
    "Beyond the measure $m$, the Porter stemming algorithms also defines the following conditions\n",
    "\n",
    "* $^*S$ &mdash; the stem ends with $S$ (and similarly for the other letters)\n",
    "* $*v*$  &mdash; the stem contains a vowel\n",
    "* $*d$  &mdash; the stem ends with a double consonant (e.g. *\"-TT\"*, \"*-SS*\")\n",
    "* $*o$  &mdash; the stem ends `cvc`, where the second `c` is not *W*, *X* or *Y* (e.g., *\"-WIL\"*, *\"-HOP'*)\n",
    "\n",
    "The individual conditions can be combined using negation, the logical *\"and\"* and logical *\"or\"* to form more complex conditions. For example, the condition\n",
    "\n",
    "$$\\large\n",
    "(*d\\ \\text{and}\\ \\text{not}\\ (*L\\ \\text{or}\\ *S\\ \\text{or}\\ *Z))\n",
    "$$\n",
    "\n",
    "test if a stems ends with a double consonant and does not end with letters \"L*, *S* or *Z*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a644f2-758f-4cab-b02e-a889ab713618",
   "metadata": {},
   "source": [
    "### Application of Rules\n",
    "\n",
    "The original Porter Stemmer algorithm defines 8 rule sets which are applied sequentially. Each rule set is a list of rules that get tested and applied when the condition evaluates to *true*. If any rule of a rule set gets applied to an input word the rule set is done &mdash; that is, not other rules and the same rule set get checked, and the algorithm moves to the next rule set.\n",
    "\n",
    "The class `MyPorterStemmer` implements the method `_apply_rule_list()` that takes a word and a list of rules as input. The method iterates to the list of rules, to see if a rules is applicable (i.e., if the condition of the current rule evaluates to *true*). If this is the case, the method applies this rule and immediately returns the result (again, because no further rules are supposed to be checked).\n",
    "\n",
    "The code cell below shows an example. The list of rules reflect the first rule set evaluated over a given word. In the given implementation, each rule has the form $(S1, S2, condition)$. In the rule set below, all conditions are `None` which simply means that the rules are always applied if the word ends with $S1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c8bd5c4-9bbb-457e-a11f-6044abbb0acd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abilities ==> abiliti\n"
     ]
    }
   ],
   "source": [
    "word = \"abilities\"\n",
    "\n",
    "rules = [\n",
    "    (\"sses\", \"ss\", None),  # SSES -> SS\n",
    "    (\"ies\", \"i\", None),    # IES  -> I\n",
    "    (\"ss\", \"ss\", None),    # SS   -> SS\n",
    "    (\"s\", \"\", None),       # S    ->\n",
    "]\n",
    "\n",
    "print(f\"{word} ==> {stemmer._apply_rule_list(word, rules)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf8b216-4f4c-4201-a826-21c8da16dbf9",
   "metadata": {},
   "source": [
    "Note the that the output *\"abiliti\"* for the word *\"abilities\"* is not the final stemmed version of the word as further rule set will be evaluated. The Porter Stemmer algorithm denotes these rule sets as *steps* to highlight that these rule sets are evaluated and potentially applied in sequential order. Let's go through all steps to what they are checking."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b200053-ff79-4a91-ba7a-d97668341788",
   "metadata": {},
   "source": [
    "#### Step 1a\n",
    "\n",
    "Step 1a mainly addresses the plural form of nouns as well as the 3rd-person singular for of verbs. More specifically, the rules are:\n",
    "\n",
    "* $SSES \\rightarrow SS$\n",
    "* $IES \\rightarrow I$\n",
    "* $SS \\rightarrow SS$\n",
    "* $S \\rightarrow$\n",
    "\n",
    "We already saw how the rules for Step 1a are implemented and evaluated by the `_apply_rule_list()`; see above. The code cell below applies Step 1a to the list of words; feel free to modify the list and inspect the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a66a07f-63ac-402c-b73e-3bbd7222e2c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abilities ==> abiliti\n",
      "busses ==> buss\n",
      "sings ==> sing\n",
      "class ==> class\n",
      "classes ==> class\n"
     ]
    }
   ],
   "source": [
    "words = [\"abilities\", \"busses\", \"sings\", \"class\", \"classes\"]\n",
    "\n",
    "for word in words:\n",
    "    print(f\"{word} ==> {stemmer._step1a(word)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e63690-72fd-4bf5-95c9-f23a3b4aeddf",
   "metadata": {},
   "source": [
    "#### Step 1b\n",
    "\n",
    "Step 1b focuses on handling the past tense form and progressive of verbs by applying the following rules:\n",
    "\n",
    "* $(m>0)\\ EED \\rightarrow EE$\n",
    "* $(*v*)\\ ED\\ \\rightarrow$\n",
    "* $(*v*)\\ ING\\ \\rightarrow$\n",
    "\n",
    "Let's look a some examples, but only focusing on the first rule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a59a2cd4-0bf6-4bc9-b0d7-9cf55588f1c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "freed ==> freed\n",
      "succeed ==> succee\n"
     ]
    }
   ],
   "source": [
    "words = [\"freed\", \"succeed\"]\n",
    "\n",
    "for word in words:\n",
    "    print(f\"{word} ==> {stemmer._step1b(word)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550cfa5a-27eb-4d68-89f1-f8a96e735e5c",
   "metadata": {},
   "source": [
    "Notice that *\"freed\"* has not been stemmed as the part before *\"eed\"* (i.e., *\"fr\"*) has measure of $m=0$, and therefore the condition $m>0$ evaluates to *false*.\n",
    "\n",
    "Rules 2 and 3 get additional treatments. This is due to the basic distinction between how the past tense and progressive form of verbs is formed. If the word is a regular verb ending with a consonant, the suffixes *\"-ed\"* and *\"-ing\"* are added to form the past tense and progressive form, respectively. However, there is the exception that if the verb has only one-syllable and ending in one consonant letter preceded by one vowel letter, the final consonant letter is doubled first (with the additional exceptions that *\"w\"*, *\"x\"*, and *\"y\"* never get doubled). Examples of such words include *\"swim\"*, *\"get\"*, \"fix\", etc. In contrast, if a verb ends with a *\"e\"*, this *\"e\"* is dropped before adding the suffixes *\"-ed\"* and *\"-ing\"*. This means if we stem a word like *\"exhaled\"*, we want to add the *\"e\"* back in after removing *\"-ed\"*. Therefore Step 1b includes additional rules to handle those cases. Let's check out some examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52f83eae-6f5e-4c70-b458-e90717c653d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "swimming ==> swim\n",
      "fixed ==> fix\n",
      "begged ==> beg\n",
      "begging ==> beg\n",
      "controlling ==> controll\n"
     ]
    }
   ],
   "source": [
    "words = [\"swimming\", \"fixed\", \"begged\", \"begging\", \"controlling\"]\n",
    "\n",
    "for word in words:\n",
    "    print(f\"{word} ==> {stemmer._step1b(word)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2dfeca-1bc8-45f0-8a97-04c5cbcc6455",
   "metadata": {},
   "source": [
    "#### Step 1c\n",
    "\n",
    "Step 1c is all about word ending with *\"y\"* and has only a single rule:\n",
    "\n",
    "* $(*v*)\\ Y \\rightarrow I$\n",
    "\n",
    "In other word, if the word contains a vowel, replace the *\"y\"* with a *\"i\"*. In English, many words with *\"y\"* at the end take an *\"i\"* when forming derived forms or suffixes (e.g., *\"happy\"* $\\rightarrow$ *\"happiness\"*, *\"cry\"* $\\rightarrow$ *\"cried\"*. To handle these variations consistently, the Porter Stemmer replaces *\"y\"* with *\"i\"* during the stemming process. This helps group related word forms (e.g., *\"happy\"* and *\"happiness\"*) under the same base. The code cell below shows a few examples of the effect of Step 1c."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27c7280d-c389-46f0-9183-20d95cf92e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baby ==> babi\n",
      "slowly ==> slowli\n",
      "cry ==> cry\n",
      "fully ==> fulli\n",
      "immediately ==> immediateli\n"
     ]
    }
   ],
   "source": [
    "words = [\"baby\", \"slowly\", \"cry\", \"fully\", \"immediately\"]\n",
    "\n",
    "for word in words:\n",
    "    print(f\"{word} ==> {stemmer._step1c(word)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0050d8-6a56-4a31-ac56-ee16e8b77aa1",
   "metadata": {},
   "source": [
    "### Step 2\n",
    "\n",
    "Step 2 of the Porter Stemmer algorithm plays a crucial role in refining the stemming process by handling longer suffixes that are often found in derived words. This step targets suffixes such as *\"-ational\"*, *\"-ization\"*, and *\"-fulness\"*, which frequently appear in formal or technical language. Step 2 applies transformations carefully, with conditions to ensure accuracy. For one, a suffix is only replaced if the remaining stem satisfies certain structural criteria (e.g., having a measure $m>0$, indicating that the stem contains at least one vowel-consonant pair). This prevents over-stemming and helps maintain meaningful stems. The complete list of rules as defined be the original Porter Stemmer algorithm is:\n",
    "\n",
    "* $(m>0)\\ ATIONAL \\rightarrow ATE$\n",
    "* $(m>0)\\ TIONAL \\rightarrow TION$\n",
    "* $(m>0)\\ ENCI \\rightarrow ENCE$\n",
    "* $(m>0)\\ ANCI \\rightarrow ANCE$\n",
    "* $(m>0)\\ IZER \\rightarrow IZE$\n",
    "* $(m>0)\\ ABLI \\rightarrow ABLE$\n",
    "* $(m>0)\\ ALLI \\rightarrow AL$\n",
    "* $(m>0)\\ ENTLI \\rightarrow ENT$\n",
    "* $(m>0)\\ ELI \\rightarrow E$\n",
    "* $(m>0)\\ OUSLI \\rightarrow OUS$\n",
    "* $(m>0)\\ IZATION \\rightarrow IZE$\n",
    "* $(m>0)\\ ATION \\rightarrow ATE$\n",
    "* $(m>0)\\ ATOR \\rightarrow ATE$\n",
    "* $(m>0)\\ ALISM \\rightarrow AL$\n",
    "* $(m>0)\\ IVENESS \\rightarrow IVE$\n",
    "* $(m>0)\\ FULNESS \\rightarrow FUL$\n",
    "* $(m>0)\\ OUSNESS \\rightarrow OUS$\n",
    "* $(m>0)\\ ALITI \\rightarrow AL$\n",
    "* $(m>0)\\ IVITI \\rightarrow IVE$\n",
    "* $(m>0)\\ BILITI \\rightarrow BLE$\n",
    "  \n",
    "From looking at those rules it is rather obvious that Step 2 assumes the Step 1c was already performed to replace the last *\"y\"* in a word with an *\"i\"*. Thus, for the example shown below focus on words that do not originally end and *\"y\"*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a8fa0d2-7524-4e29-ab80-e3652a723aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seriousness ==> serious\n",
      "creator ==> creator\n",
      "organization ==> organize\n",
      "organizer ==> organize\n"
     ]
    }
   ],
   "source": [
    "words = [\"seriousness\", \"creator\", \"organization\", \"organizer\"]\n",
    "\n",
    "for word in words:\n",
    "    print(f\"{word} ==> {stemmer._step2(word)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3215c64-fab5-4d89-a5f2-a38eed1d01f5",
   "metadata": {},
   "source": [
    "#### Step 3\n",
    "\n",
    "Step 3 of the Porter Stemmer algorithm focuses on refining stems further by handling suffixes associated with grammatical transformations, such as changes in part of speech or formality. This step primarily targets suffixes like *\"-ness\"*, *\"-ful\"*, *\"-ative\"*, and *\"-al\"*, reducing words to their more basic forms. The importance of this step lies in its ability to simplify derived words while maintaining their core meaning, improving the overall efficiency of text analysis tasks. Step 3 deals with suffixes that are often used to form adjectives or nouns from base words, such as: *\"-ness\"* (e.g., *\"happiness\"* $\\rightarrow$ *\"happi\"*), *\"-ative\"* (e.g., *\"informative\"* $\\rightarrow$ *\"inform\"*), or *\"-ful\"* (e.g., *\"hopeful\"* $\\rightarrow$ *\"hope\"*). Similar to Step 2, a suffix is only replaced if the remaining stem has a measure of $m>0$ to prevent over-stemming. The complete list of rules for Step 3 is:\n",
    "\n",
    "* $(m>0)\\ ICATE \\rightarrow ICE$\n",
    "* $(m>0)\\ ATIVE \\rightarrow$\n",
    "* $(m>0)\\ ALIZE \\rightarrow AL$\n",
    "* $(m>0)\\ ICITI \\rightarrow IC$\n",
    "* $(m>0)\\ ICAL \\rightarrow IC$\n",
    "* $(m>0)\\ FUL \\rightarrow$\n",
    "* $(m>0)\\ NESS \\rightarrow$\n",
    " \n",
    "Again, some of the rules assume that the suffix *\"y\"* has already been replaced with an *\"i\"*. The code cell below applies Step 3 to a few example words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7e2df93-d0cd-411d-a114-5c65c6463652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "critical ==> critic\n",
      "fearful ==> fear\n",
      "indicate ==> indic\n",
      "blindness ==> blind\n"
     ]
    }
   ],
   "source": [
    "words = [\"critical\", \"fearful\", \"indicate\", \"blindness\"]\n",
    "\n",
    "for word in words:\n",
    "    print(f\"{word} ==> {stemmer._step3(word)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf6a2b4-a9e3-4ee6-ae5f-54cadd8ae3a9",
   "metadata": {},
   "source": [
    "#### Step 4\n",
    "\n",
    "Step 4 of the Porter Stemmer algorithm is designed to remove common suffixes that act as grammatical markers in English, such as *\"-al\"*, *\"-ance\"*, *\"-ence\"*, *\"-able\"*, *\"-ible\"*, *\"-ment\"*, and others. These suffixes often appear in longer, derived words and are typically less essential to the word's core meaning. The purpose of Step 4 is to reduce such words to their bare stems by stripping away these secondary suffixes, enabling more efficient text processing and better grouping of related terms. Secondary suffixes modify the word but do not drastically alter its meaning. These suffixes often indicate abstract concepts, properties, or states. Examples include *\"-ment\"* (e.g., *\"development\"* $\\rightarrow$ *\"develop\"*), *\"-ance\"* (e.g., *\"reliance\"* $\\rightarrow$ *\"rely\"*), and *\"-able\"* (e.g., *\"readable\"* $\\rightarrow$ *\"read\"*). The exact rules are:\n",
    "\n",
    "* $(m>0)\\ AL \\rightarrow$\n",
    "* $(m>0)\\ ANCE \\rightarrow$\n",
    "* $(m>0)\\ ENCE \\rightarrow$\n",
    "* $(m>0)\\ ER \\rightarrow$\n",
    "* $(m>0)\\ IR \\rightarrow$\n",
    "* $(m>0)\\ ABLE \\rightarrow$\n",
    "* $(m>0)\\ IBLE \\rightarrow$\n",
    "* $(m>0)\\ ANT \\rightarrow$\n",
    "* $(m>0)\\ EMENT \\rightarrow$\n",
    "* $(m>0)\\ MENT \\rightarrow$\n",
    "* $(m>0)\\ ENT \\rightarrow$\n",
    "* $(m>0\\ \\text{and}\\ (*S\\ \\text{OR}\\ *T))\\ ION \\rightarrow$\n",
    "* $(m>0)\\ OU \\rightarrow$\n",
    "* $(m>0)\\ ISM \\rightarrow$\n",
    "* $(m>0)\\ ATE \\rightarrow$\n",
    "* $(m>0)\\ ITI \\rightarrow$\n",
    "* $(m>0)\\ OUS \\rightarrow$\n",
    "* $(m>0)\\ IVE \\rightarrow$\n",
    "* $(m>0)\\ IZE \\rightarrow$\n",
    "  \n",
    "To show the effects of Step 4, let's look at some examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b4a3a54-e70e-414d-a474-5df86301b338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replacement ==> replac\n",
      "tolerant ==> toler\n",
      "difference ==> differ\n",
      "activism ==> activ\n"
     ]
    }
   ],
   "source": [
    "words = [\"replacement\", \"tolerant\", \"difference\", \"activism\"]\n",
    "\n",
    "for word in words:\n",
    "    print(f\"{word} ==> {stemmer._step4(word)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b753e8e6-68a6-49aa-9e47-585551910ebf",
   "metadata": {},
   "source": [
    "#### Step 5a\n",
    "\n",
    "Step 5a of the Porter Stemmer algorithm is focused on removing a final *\"e\"* from words under specific conditions. The purpose of this step is to simplify words to their most basic form without stripping away meaning. Since many English words end with a silent *\"e\"* that does not contribute to the word's core meaning, removing it can produce cleaner, more generalized stems for text processing tasks.  The final *\"e\"* often serves as a grammatical or phonetic marker rather than contributing to the meaning of the word, e.g., *\"probate\"* $\\rightarrow$ *\"probat\"*, *\"cease\"* $\\rightarrow$ *\"ceas\"*. The two specific rules are:\n",
    "\n",
    "* $(m>1)\\ E \\rightarrow$\n",
    "* $(m=1\\ \\text{and}\\ \\text{not}\\ *o)\\ E \\rightarrow$\n",
    "\n",
    "The code cell below runs Step 5 for a few example words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "51a01f8f-10cc-4928-b4dc-83a6b4975de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probate ==> probat\n",
      "rate ==> rate\n",
      "accelerate ==> accelerat\n",
      "cease ==> ceas\n"
     ]
    }
   ],
   "source": [
    "words = [\"probate\", \"rate\", \"accelerate\", \"cease\"]\n",
    "\n",
    "for word in words:\n",
    "    print(f\"{word} ==> {stemmer._step5a(word)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb39b0a-9fd2-447f-aeea-18201a451070",
   "metadata": {},
   "source": [
    "#### Step 5b\n",
    "\n",
    "The purpose of Step 5b in the Porter Stemmer algorithm is to remove a redundant *\"l\"* from words ending in *\"ll\"*, provided the stem meets a specific measure condition ($m>1$). This step further simplifies word forms, ensuring consistency across related terms while avoiding over-stemming. As the final step of the algorithm, it fine-tunes the stems, making them ready for use in text analysis, retrieval, and other NLP tasks. The single rule of Step 5b is:\n",
    "\n",
    "* $(m>1\\ \\text{and}\\ *d\\ \\text{and}\\ *L)\\ \\rightarrow L$\n",
    "\n",
    "Let's check out a few examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1780d493-806e-47fb-86db-aa5d8626a93b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full ==> full\n",
      "recall ==> recal\n",
      "enroll ==> enrol\n"
     ]
    }
   ],
   "source": [
    "words = [\"full\", \"recall\", \"enroll\"]\n",
    "\n",
    "for word in words:\n",
    "    print(f\"{word} ==> {stemmer._step5b(word)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8e28bb-ec0e-4bb6-928b-836cfd34e328",
   "metadata": {},
   "source": [
    "As usual, keep in mind that Step 5c will be applied after all previous steps. This might include words such as *\"controlling\"* will be stemmed to *\"controll\"* in Step 1b; and therefore further stemmed to *\"control\"* in Step 5."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5edfad0b-33b5-48bc-a3da-aa0a05054637",
   "metadata": {},
   "source": [
    "#### Applying of all Rules\n",
    "\n",
    "Now that we covered all 8 steps of the Porter Stemming algorithm, we apply them to a few example words to see the full effect of this stemming algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a758276-58eb-4872-a872-abc0de9d38ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abilities ==> abil\n",
      "aggressivness ==> aggressiv\n",
      "running ==> run\n",
      "run ==> run\n",
      "see ==> see\n",
      "international ==> intern\n",
      "organization ==> organ\n",
      "controlling ==> control\n",
      "nervousness ==> nervous\n",
      "accomplishment ==> accomplish\n"
     ]
    }
   ],
   "source": [
    "words = [\"abilities\", \"aggressivness\", \"running\", \"run\", \"see\", \"international\", \n",
    "         \"organization\", \"controlling\", \"nervousness\", \"accomplishment\"]\n",
    "\n",
    "for word in words:\n",
    "    print(f\"{word} ==> {stemmer.stem(word)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3242dfd-7b49-469e-a926-43d75e800ccd",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0c42ce-8cac-4928-8369-b723836b1101",
   "metadata": {},
   "source": [
    "## Limitations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eefd8725-2ddb-4b6b-856e-34ab54e76f67",
   "metadata": {},
   "source": [
    "### Language-Specific\n",
    "\n",
    "As the most obvious limitation, the Porter Stemmer is specifically designed for English text because it relies on rules tailored to the morphology and grammar of the English language. Stemming for any language must consider its unique linguistic characteristics, such as word formation rules, suffixes, and grammatical structure. In fact, with respect to stemming, English can be considered a rather simple language, requiring only a relatively smaller set of rules to yield good results. Other language often pose bigger challenges for designing an effective stemming algorithm; common reasons include:\n",
    "\n",
    "* **Complex Morphology:** Some languages have more complex word structures than English, with rich inflectional or derivational forms. For example Agglutinative Languages (e.g., Turkish, Finnish) have words that can consist of long chains of morphemes, each adding specific grammatical meaning. For example, in Turkish, *\"evlerinizden\"* (*\"from your houses\"*) contains multiple affixes that need to be carefully stripped. Fusional Languages (e.g., Russian, Spanish) have words where a single suffix can encode multiple grammatical properties, such as tense, mood, and number, making it harder to design rules for consistent stemming.\n",
    "\n",
    "* **Non-Latin Scripts:** Languages written in non-Latin scripts, such as Arabic, Hindi, or Chinese, pose unique challenges. For example, in Arabic, root-based morphology means that words are formed from three-letter roots, often requiring root extraction rather than suffix removal. Chinese and Japanese use logographic or syllabic scripts, meaning words are not formed with prefixes and suffixes. Instead of stemming, segmentation (splitting sentences into words) is a prerequisite.\n",
    "\n",
    "* **Compound Words:** Languages like German and Dutch frequently use compound words: For example, in German, *\"Hausmeisterwohnung\"* (*\"caretaker's apartment\"*) combines *\"Haus\"* (*\"house\"*), *\"Meister\"* (*\"master\"*), and *\"Wohnung\"* (*\"apartment\"*). Stemming must recognize and split such compounds before processing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d5d8ca-5b52-41d2-b3a4-af2457508f4b",
   "metadata": {},
   "source": [
    "### Common Failure Types\n",
    "\n",
    "* **Irregular Word Forms:** The Porter Stemmer does not handle irregular word forms or exceptions well because it relies on fixed rules rather than a dictionary or semantic understanding. For example, the stemmer does not affect words such as *\"better\"* or *\"went\"*, since only removing suffixes does not allow to map to *\"good\"* and *\"go\"*, respectively\n",
    "\n",
    "* **Over-Stemming:** Over-stemming happens when the algorithm reduces words to stems that are too short or unrelated, causing semantically distinct words to collapse into the same stem. For example, The two words *\"university\"*  and *\"universe\"* have distinct meanings, but they are reduced to the same stem *\"univers\"*, leading to loss of differentiation.\n",
    "\n",
    "* **Under-Stemming:** Under-stemming occurs when the stemming algorithm reduces inflected words to different word stems, but they should be the same. For example, the Porter Stemmer algorithm does not reduce the words *\"alumnus\"*, *\"alumnae\"*, and *\"alumni\"* to the same word stem, although they should be treated as synonyms. It easy to see that this is likely to happen from words directly borrow from other languages and therefore not adhere to rules commonly found in the English language."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc64f67f-bac7-4543-96d0-097286bf32a2",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f2f6b3-698a-4a5a-a795-24c790a2e885",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "The Porter Stemmer is an algorithm used in natural language processing (NLP) to reduce words to their root or base form, called the stem. For example, words like running, runner, and runs are simplified to run. It uses a series of rules to strip suffixes like -ing, -ed, or -ly, focusing on English words. This helps standardize words so that similar ones are grouped together, making it easier for computers to process and analyze text.\n",
    "\n",
    "This algorithm is especially important in tasks like search engines, text classification, and sentiment analysis. By reducing words to their stems, it ensures that different forms of the same word are treated as one, improving the accuracy of tasks like finding relevant search results or identifying patterns in text. While the Porter Stemmer isn't perfect &mdash; it may sometimes oversimplify or fail to connect related words &mdash; it remains a widely used tool because it is simple, fast, and effective for many applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de68bf18-e92d-46d4-8caf-955c590b3e94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
